{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2025-01-19'\n",
    "data = pd.read_csv('../data/oresund/'+date+'.csv') #Import data\n",
    "data = data.drop_duplicates() #Drop duplicates (there are many!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a copy to manipulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filter = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering out helicopters which are faster than 60 knots (or else it's a spurious incident)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I filter for helicopter\n",
    "data_filter = data_filter[(data_filter['SOG'] < 60) | (data_filter['SOG'].isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling the series so there's a minimum five minute interval between measurements\n",
    "This period is of coursse arbitrary, but seems to be a good compromise between memory and resolution\n",
    "A ship moves $5/60 \\cdot 20 \\approx 1.6 km$ when sailing fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/29/jqsnm5js6_sc7663vjsq3mp40000gp/T/ipykernel_9510/3287667159.py:12: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data_temp = pd.concat([data_temp, ship], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "data_temp = pd.DataFrame(columns=data_filter.columns)\n",
    "\n",
    "for MMSI in data_filter['MMSI'].unique():\n",
    "    ship = data_filter[data_filter['MMSI'] == MMSI]\n",
    "    #Creating a series for time filtering\n",
    "    series = pd.Series(range(len(ship)), index=pd.to_datetime(ship['# Timestamp'], dayfirst=True))\n",
    "    #Resampling the series to 5 minutes. This gives the index of the last data point in the 5 minute interval\n",
    "    #The unique is added because if transmission occurs less frequently than 5 mins there will be duplicates\n",
    "    resampled = series.resample('5min').first().dropna().astype(int)\n",
    "    #Filtering the data\n",
    "    ship = ship.iloc[resampled]\n",
    "    data_temp = pd.concat([data_temp, ship], ignore_index=True)\n",
    "\n",
    "data_filter = data_temp.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we filter out buoys and aids to navigation ('base station' and 'AtoN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Class A' 'Class B' 'Base Station' 'AtoN']\n",
      "['Class A' 'Class B']\n",
      "67423\n"
     ]
    }
   ],
   "source": [
    "print(data['Type of mobile'].unique())\n",
    "data_filter = data_filter[(data_filter['Type of mobile']!='Base Station') & (data_filter['Type of mobile']!='AtoN')]\n",
    "print(data_filter['Type of mobile'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appending the dataset with distance measure which is signed depending on whether ship is north or south of Oresund (see Trials/Oresund_distance_calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining parameters for oresund bridge\n",
    "long_or = (12.682873, 12.88866)\n",
    "lat_or = (55.628996, 55.564952)\n",
    "\n",
    "#Using a flat earth approximation to calculate the slope (in lat/lon) of the bridge\n",
    "slope_or = (lat_or[1]-lat_or[0])/(long_or[1] - long_or[0])\n",
    "\n",
    "#Defining function for the corridor going perpendicular to the bridge\n",
    "def corridor_lon(lat):\n",
    "    west = -slope_or*(lat - lat_or[0]) + long_or[0]\n",
    "    east = -slope_or*(lat - lat_or[1]) + long_or[1]\n",
    "    return west, east\n",
    "\n",
    "#Calculating the corridor on the latitudes that all the ships are in\n",
    "west, east = corridor_lon(data_filter['Latitude'])\n",
    "in_corridor = data_filter['Longitude'].between(west, east) #If the ship is in the corridor\n",
    "west_of_corridor = data_filter['Longitude'] < west #If the ship is west of the corridor\n",
    "east_of_corridor = data_filter['Longitude'] > east #If the ship is east of the corridor\n",
    "\n",
    "#Calculating the distance\n",
    "lat_dist = 6378*2*np.pi/360 #Latituda distance in km using radius of earth\n",
    "lon_dist = lat_dist * np.cos(lat_or[0]*np.pi/180) #Longitude distance in km using radius of earth and latitude of bridge\n",
    "\n",
    "#\"distance\" coordinates of each ship (will convert to real distances when subtracted from the bridge)\n",
    "x = data['Longitude']*lon_dist\n",
    "y = data['Latitude']*lat_dist\n",
    "\n",
    "x_or = np.array(long_or)*lon_dist\n",
    "y_or = np.array(lat_or)*lat_dist\n",
    "\n",
    "bridge_vec_deg = np.array([1, slope_or]) #Bridge vector in degrees\n",
    "bridge_vec_dist = bridge_vec_deg * np.array([lon_dist, lat_dist]) #Bridge vector in km\n",
    "n = np.array([-bridge_vec_dist[1], bridge_vec_dist[0]]) #Normal vector to the bridge vector in km\n",
    "n = n/np.linalg.norm(n) #Normalized normal vector\n",
    "perp_dist = (x-x_or[0])*n[0] + (y-y_or[0])*n[1] #Perpendicular distance using projection onto normal vector\n",
    "above = (perp_dist > 0)*2 - 1 #If the ship is above or below the bridge\n",
    "dist_west = above*np.sqrt((x-x_or[0])**2 + (y-y_or[0])**2) #Signed distance to the west bridge point\n",
    "dist_east = above*np.sqrt((x-x_or[1])**2 + (y-y_or[1])**2) #Signed distance to the east bridge point\n",
    "\n",
    "#If the ship is in corridor use the perpendicular distance, else use the closest distance to the bridge\n",
    "data['Distance'] = perp_dist * in_corridor + dist_west * west_of_corridor + dist_east * east_of_corridor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the real dataset \\\n",
    "Every datapoint is a triple with (distance, speed, time to cross)\n",
    "\n",
    "Loop over all ships and\n",
    "1) Decide if ship is crossing\n",
    "2) Find time of crossing\n",
    "3) Calculate time until crossing\n",
    "4) Calculate speed\n",
    "5) Append all relevant datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame(columns=['Distance', 'SOA', 'TTC'])\n",
    "\n",
    "for MMSI in data_filter['MMSI'].unique():\n",
    "    ship = data_filter[data_filter['MMSI'] == MMSI]\n",
    "    dist = ship['Distance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Down here are demonstrations of the workings of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  3  7  9 11 12 13 16 19 21 24 27 28 32 35]\n",
      "124      19/01/2025 00:00:08\n",
      "6251     19/01/2025 00:06:09\n",
      "13371    19/01/2025 00:12:57\n",
      "15785    19/01/2025 00:15:08\n",
      "25406    19/01/2025 00:24:08\n",
      "28485    19/01/2025 00:27:10\n",
      "31475    19/01/2025 00:30:08\n",
      "37779    19/01/2025 00:36:08\n",
      "43849    19/01/2025 00:42:10\n",
      "50235    19/01/2025 00:48:08\n",
      "53439    19/01/2025 00:51:09\n",
      "60392    19/01/2025 00:57:10\n",
      "63752    19/01/2025 01:00:09\n",
      "70313    19/01/2025 01:06:09\n",
      "77721    19/01/2025 01:12:57\n",
      "Name: # Timestamp, dtype: object\n",
      "874      19/01/2025 00:00:57\n",
      "9518     19/01/2025 00:09:09\n",
      "13404    19/01/2025 00:12:59\n",
      "19997    19/01/2025 00:18:58\n",
      "25406    19/01/2025 00:24:08\n",
      "28485    19/01/2025 00:27:10\n",
      "34724    19/01/2025 00:33:08\n",
      "40840    19/01/2025 00:39:09\n",
      "44724    19/01/2025 00:42:58\n",
      "51100    19/01/2025 00:48:58\n",
      "57699    19/01/2025 00:54:57\n",
      "60392    19/01/2025 00:57:10\n",
      "67066    19/01/2025 01:03:10\n",
      "73630    19/01/2025 01:09:09\n",
      "77721    19/01/2025 01:12:57\n",
      "Name: # Timestamp, dtype: object\n",
      "124      19/01/2025 00:00:08\n",
      "873      19/01/2025 00:00:57\n",
      "874      19/01/2025 00:00:57\n",
      "6251     19/01/2025 00:06:09\n",
      "7178     19/01/2025 00:06:57\n",
      "7181     19/01/2025 00:06:58\n",
      "9518     19/01/2025 00:09:09\n",
      "13371    19/01/2025 00:12:57\n",
      "13404    19/01/2025 00:12:59\n",
      "15785    19/01/2025 00:15:08\n",
      "19997    19/01/2025 00:18:58\n",
      "25406    19/01/2025 00:24:08\n",
      "28485    19/01/2025 00:27:10\n",
      "31475    19/01/2025 00:30:08\n",
      "32429    19/01/2025 00:30:58\n",
      "Name: # Timestamp, dtype: object\n"
     ]
    }
   ],
   "source": [
    "ship = data[data['MMSI'] == data['MMSI'].values[49]]\n",
    "series = pd.Series(range(len(ship)), index=pd.to_datetime(ship['# Timestamp'], dayfirst=True))\n",
    "resampled = series.resample('5min')\n",
    "ind_1 = resampled.first().dropna().astype(int)\n",
    "ind_2 = (resampled.count().cumsum()-1).unique()\n",
    "print(ind_1.values[:15])\n",
    "print(ship.iloc[ind_1]['# Timestamp'][:15])\n",
    "print(ship.iloc[ind_2]['# Timestamp'][:15])\n",
    "print(ship['# Timestamp'][:15])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
