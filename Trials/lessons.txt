To-dos:
1) Try using dask or something optimized for out-of-core computing since the whole dataset cannot
at all be loaded all at once

2) Explore the oresund dataset and see if there is something interesting to do!

3) Organise dataset and find out what ships and when they cross øresundsbroen

3) Do some kind of basic estimate (not even a fitted model) to expose some structure. Identify moving ships!


Lessons:
1) Doing a single comparison on data for ONE day takes 3 min (selecting a single ship to plot trajectory) (1 min mac)

2) Et tilfældigt skib jeg tog ud har 37000 entries for én dag... Hvert datapunkt er duplikeret 4 gange
(måske med forskellige positioneringssystemer???)
2.1) Der er 37.500.000 entries for en tilfældig januardag
2.2) Oresund data took 14 mins in pandas (9 mins mac)
2.3) Cleanup data before savig. I need to filter stuff!!!

3) Øresundsbroen forbinder (55.628996, 12.682873) og (55.564952, 12.88866)


Immediate to-do:
Identify what ships crosses Oresund - DONE
Find criteria for when ship is "present" and "not present" for the model
Try and build a basic "model" that filters out not moving ships and provides a basic estimate for moving ships.
    see if results are somehow reasonable...
Reorganize data into single ship dictionary (torch dataset?)